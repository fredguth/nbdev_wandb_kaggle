{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to provide a minimum viable pipeline using [fastai](https://docs.fast.ai/) for classification and detection of opacity in xray images. Anyone who is new to this competition can start from this notebook and learn the followings:\n",
    "\n",
    "* Basic understanding of the nature of medical imaging data\n",
    "* Introduction to fastai library for [medical imaging](https://docs.fast.ai/medical.imaging)\n",
    "* Submission of predictions\n",
    "\n",
    "The progress is as following:\n",
    "\n",
    "    1. Data Overview           (Done)\n",
    "    2. Data Preprocessing      (Done)\n",
    "    3. Preparing Datablock     (Done)\n",
    "    4. Training                (Done)\n",
    "    5. Predictions             (tbd, predict() not yet available)\n",
    "    6. Subsmission             (tdb)\n",
    "\n",
    "I am using following 2 notebooks as reference:\n",
    "* https://www.kaggle.com/avirdee/siim-covid-19-initial-pipeline-fastai\n",
    "* https://github.com/muellerzr/Practical-Deep-Learning-for-Coders-2.0/blob/master/Computer%20Vision/06_Object_Detection.ipynb\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: glob2 in /home/fredguth/.miniconda/lib/python3.8/site-packages (0.7)\n",
      "Requirement already satisfied: tqdm in /home/fredguth/.miniconda/lib/python3.8/site-packages (4.59.0)\n"
     ]
    }
   ],
   "source": [
    "# Load Grassroots DICOM (GDCM) for xray DICOM files\n",
    "!pip install python-gdcm -q\n",
    "\n",
    "# Load glob2\n",
    "!pip install glob2\n",
    "\n",
    "# Load tqdm\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary packages\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob2\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import gdcm\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from fastai.vision.all import *\n",
    "from fastai.medical.imaging import *\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fredguth/kaggle/covid19\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/siim-covid19-detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bbafac8cdee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSOURCE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/input/siim-covid19-detection'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOURCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/siim-covid19-detection'"
     ]
    }
   ],
   "source": [
    "SOURCE = '/kaggle/input/siim-covid19-detection'\n",
    "os.listdir(SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_level = pd.read_csv(f'{SOURCE}/train_image_level.csv')\n",
    "train_study_level = pd.read_csv(f'{SOURCE}/train_study_level.csv')\n",
    "sample_submission = pd.read_csv(f'{SOURCE}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_study_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XRAY Files\n",
    "def get_dcm_files(path, recurse=True, folders=None):\n",
    "    \"Get image files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=['.dcm'], recurse=recurse, folders=folders)\n",
    "\n",
    "# Read DICOM files\n",
    "TRAIN_DIR = f'{SOURCE}/train/'\n",
    "TEST_DIR =  f'{SOURCE}/test/'\n",
    "train_dcm = get_dcm_files(TRAIN_DIR)\n",
    "test_dcm = get_dcm_files(TEST_DIR)\n",
    "\n",
    "# Looking on a sample XRAY\n",
    "xray_sample = train_dcm[1].dcmread()\n",
    "xray_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xray_sample.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging study_level and image_level\n",
    "# rename id column in study_level to StudyInstanceUID\n",
    "train_study_level.rename(columns = {'id':'StudyInstanceUID'}, inplace = True)\n",
    "\n",
    "# remove _study from StudyInstanceUID\n",
    "train_study_level['StudyInstanceUID'] = train_study_level['StudyInstanceUID'].str.replace('_study', '')\n",
    "\n",
    "# merge\n",
    "df_train = pd.merge(train_image_level, train_study_level, on='StudyInstanceUID')\n",
    "\n",
    "# remove _image from id column\n",
    "df_train['id'] = df_train['id'].str.replace('_image', '')\n",
    "\n",
    "# rename id column as imageID\n",
    "df_train.rename(columns = {'id':'imageID'}, inplace = True)\n",
    "\n",
    "# renaming target columns\n",
    "df_train.rename(columns = {'Negative for Pneumonia':'negative'}, inplace = True)\n",
    "df_train.rename(columns = {'Typical Appearance':'typical'}, inplace = True)\n",
    "df_train.rename(columns = {'Indeterminate Appearance':'indeterminate'}, inplace = True)\n",
    "df_train.rename(columns = {'Atypical Appearance':'atypical'}, inplace = True)\n",
    "\n",
    "# Create a new target column\n",
    "categories = ['negative','typical','indeterminate','atypical']\n",
    "df = df_train[categories]\n",
    "df_train[\"target\"] = pd.Series(df.columns[np.where(df!=0)[1]])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating path column for each image\n",
    "TRAIN_DIR = f'{SOURCE}/train/'\n",
    "paths = []\n",
    "\n",
    "for instance_id in tqdm(df_train['StudyInstanceUID']):\n",
    "    paths.append(glob.glob(os.path.join(TRAIN_DIR, instance_id +\"/*/*\"))[0])\n",
    "\n",
    "df_train['path'] = paths\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of bounding boxes\n",
    "# Source: https://www.kaggle.com/avirdee/siim-covid-19-initial-pipeline-fastai\n",
    "num_of_boxes = []\n",
    "for i in df_train.index:\n",
    "    val_len = len(df_train['label'][i].split(' '))\n",
    "    val = df_train['label'][i].split(' ')\n",
    "    label = df_train['target'][i]\n",
    "    box_count = val_len//6\n",
    "    num_of_boxes.append(box_count)\n",
    "    \n",
    "df_train['num_of_boxes'] = num_of_boxes\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['num_of_boxes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse label column\n",
    "bboxes = []\n",
    "for i in df_train.index:\n",
    "    num_of_boxes = df_train['num_of_boxes'][i]\n",
    "    val = df_train['label'][i].split(' ')\n",
    "    if num_of_boxes == 1: boxes = val[2:6]\n",
    "    if num_of_boxes == 2: boxes = val[2:6] + val[8:12]\n",
    "    if num_of_boxes == 3: boxes = val[2:6] + val[8:12] + val[14:18]\n",
    "    if num_of_boxes == 4: boxes = val[2:6] + val[8:12] + val[14:18] + val[20:24]\n",
    "    bboxes.append(boxes)\n",
    "    \n",
    "df_train['parsed_label'] = bboxes\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preparing DataBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting df_train on columns required for datablock\n",
    "df_datablock = df_train[['imageID', 'target', 'parsed_label', 'path']].copy()\n",
    "df_datablock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining get_items() as Path() object to file\n",
    "im_df = df_datablock['path'].unique()\n",
    "fns = [Path(str(f'{fn}')) for fn in im_df]\n",
    "#fns[:5]\n",
    "\n",
    "def get_items(noop): return fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frame to numpy array for faster processing\n",
    "df_np = df_datablock.to_numpy()\n",
    "df_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tmp_bbox(fn):\n",
    "    rows = np.where(df_np[:,0] == fn.name[:-4])\n",
    "    bboxs = df_np[rows][:,-2][0]\n",
    "    return np.array([np.fromstring(b, sep=',') for b in bboxs])\n",
    "\n",
    "def get_tmp_lbl(fn):\n",
    "    rows = np.where((df_np[:, 0] == fn.name[:-4]))\n",
    "    bboxs = len(df_np[rows][:,-2][0])\n",
    "    if bboxs > 12:\n",
    "        return np.concatenate(([df_np[rows][:,1]]*4))\n",
    "    if bboxs > 8:\n",
    "        return np.concatenate(([df_np[rows][:,1]]*3))\n",
    "    if bboxs > 4:\n",
    "        return np.concatenate(([df_np[rows][:,1]]*2))\n",
    "    else:\n",
    "        return df_np[rows][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tmp_bbox(get_items(SOURCE)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tmp_lbl(get_items(SOURCE)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxs = get_tmp_bbox(fns[0])\n",
    "lbls = get_tmp_lbl(fns[0])\n",
    "arr = np.array([fns[0].name[:-4], bboxs, lbls], dtype=object)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole dataset\n",
    "for path in fns[1:]:\n",
    "    bbox = get_tmp_bbox(path)\n",
    "    lbl = get_tmp_lbl(path)\n",
    "    arr2 = np.array([path.name[:-4], bbox, lbl], dtype='object')\n",
    "    arr = np.vstack((arr, arr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(fn):\n",
    "    idx = np.where((arr[:,0] == fn.name[:-4]))\n",
    "    return arr[idx][0][1]\n",
    "\n",
    "def get_lbl(fn):\n",
    "    idx = np.where((arr[:,0] == fn.name[:-4]))\n",
    "    return arr[idx][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bbox(get_items(SOURCE)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_lbl(get_items(SOURCE)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/avirdee/siim-covid-19-initial-pipeline-fastai\n",
    "class HistView(PILDicom):\n",
    "    \"View histogram scaled version of the pixel array\"\n",
    "    @classmethod\n",
    "    def create(cls, fn:(Path, str, bytes))->None:\n",
    "        if isinstance(fn, bytes): im = pydicom.dcmread(pydicom.filebase.DicomBytesIO(fn))\n",
    "        if isinstance(fn, (Path, str)): im = pydicom.dcmread(fn)\n",
    "        scaled = np.array(im.hist_scaled())\n",
    "        scaled = scaled - np.min(scaled)\n",
    "        scaled = scaled / np.max(scaled)\n",
    "        scaled = (scaled * 255).astype(np.uint8)\n",
    "        pill_im = Image.fromarray(scaled)\n",
    "        return cls(pill_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(7)\n",
    "datablock = DataBlock(blocks=(ImageBlock(cls=HistView), BBoxBlock, BBoxLblBlock),\n",
    "                 get_items=get_items,\n",
    "                 splitter=RandomSplitter(),\n",
    "                 get_y=[get_bbox, get_lbl],\n",
    "                 item_tfms=[Resize(128, method='pad'),],\n",
    "                 batch_tfms=[Rotate(), Flip(), Dihedral(), Normalize.from_stats(*imagenet_stats)],\n",
    "                 n_inp=1)\n",
    "\n",
    "dls = datablock.dataloaders(TRAIN_DIR, bs=128)\n",
    "dls.show_batch(max_n=20, ncols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shape of a batch\n",
    "batch = dls.one_batch()\n",
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/muellerzr/Practical-Deep-Learning-for-Coders-2.0/blob/master/Computer%20Vision/06_Object_Detection.ipynb\n",
    "!git clone https://github.com/muellerzr/Practical-Deep-Learning-for-Coders-2.0.git\n",
    "%cd \"Practical-Deep-Learning-for-Coders-2.0/Computer Vision\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_body(resnet34, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = RetinaNet(encoder, get_c(dls), final_bias=-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "ratios = [1/2,1,2]\n",
    "scales = [1,2**(-1/3), 2**(-2/3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = RetinaNetFocalLoss(scales=scales, ratios=ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _retinanet_split(m): \n",
    "    return L(m.encoder,nn.Sequential(m.c5top6, m.p6top7, m.merges, m.smoothers, m.classifier, m.box_regressor)).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, arch, loss_func=crit, splitter=_retinanet_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2, slice(1e-5, 1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving weights of the trained model\n",
    "TRAINED_MODELS_DIR = '/kaggle/working/trained_models_dir/'\n",
    "os.mkdir(TRAINED_MODELS_DIR)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"_%Y%m%d_%H%M%S_\")\n",
    "file_name = TRAINED_MODELS_DIR + \"trainedModelWeights\" + timestamp\n",
    "learn.save(file = file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the trained model\n",
    "timestamp = datetime.now().strftime(\"_%Y%m%d_%H%M%S_\")\n",
    "file_name = TRAINED_MODELS_DIR + \"trainedModelExport\" + timestamp + \".pkl\"\n",
    "learn.export(fname = file_name)\n",
    "os.listdir(TRAINED_MODELS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img_path = TEST_DIR + '/2fb11712bc93/b056067b8455/a29c5a68b07b.dcm'\n",
    "sample_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(sample_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
