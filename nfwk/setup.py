# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_setup.ipynb (unless otherwise specified).

__all__ = ['get_kaggle_dataset', 'download_and_log']

# Cell
def get_kaggle_dataset(competition):
    'download and extract kaggle competition dataset to fastai data folder'
    config = Config()
    zipdest = Path(config.d['archive_path'])
    zipname = Path(config.d['archive_path']+'/'+competition+'.zip')
    if not zipname.exists():
        print (f'${zipname} does not exist. Downloading...')
        k.competition_download_files(competition, path=zipdest)
    dest = Path(config.d['data_path']+'/'+competition+'/')
    if not dest.exists():
        print (f'${dest} does not exist.  Extracting...')
        file_extract(zipname, dest=dest)
        files = os.listdir(dest)
        for f in files:
            if f.split('.')[-1]=='zip':
                print(dest/f)
                file_extract(dest/f)
                os.remove(dest/f)
    return dest

# Cell
def download_and_log(competition):
    # üöÄ start a run, with a type to label it and a project it can call home
    with wandb.init(project=competition, job_type="download-data") as run:
        path = get_kaggle_dataset(competition)
        sizes = {}
        raw_data = wandb.Artifact(
            competition, type="dataset",
            description=f'Raw {competition} dataset.',
            metadata={"source": "Kaggle"})
        for b, ds, _ in os.walk(path):
            for d in ds:
                files = get_image_files(b+'/'+d)
                sizes[d] = len(files)
                for f in tqdm(files):
                    raw_data.add_reference('file://'+str(f))
        raw_data.metadata['sizes']=sizes
        # ‚úçÔ∏è Save the artifact to W&B.
        run.log_artifact(raw_data)